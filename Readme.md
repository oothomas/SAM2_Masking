# ğŸ¬Â SAMâ€‘2Â /Â SAMURAI Videoâ€‘Masking Pipeline
_A zeroâ€‘shot CLI for turning raw video into photogrammetryâ€‘ready image sets_

---

## 1â€‚Why does this exist?
Building a 3â€‘D model from **video** usually starts with a slog:

1. Extract every frame.
2. Mask your object by hand.
3. Rename files and inject camera EXIF so WebODM/RealityCapture will accept them.

This repo turns that entire workflow into **one command** by wrapping
MetaÂ AIâ€™s stateâ€‘ofâ€‘theâ€‘art video segmenter
**SAMURAIÂ (SAMâ€‘2)** with a lightweight Python CLI.

> **Result**  
> Draw _one_ box â†’ receive three tidy folders:
>
> ```
> original/   # untouched RGB JPEGs
> masked/     # foregroundâ€‘only RGB + *_mask.jpg (binary)
> keyframes/  # optional (if enabled)
> ```

---

## 2â€‚What are SAMâ€‘2 and SAMURAI?
| Component | Role | Links |
|-----------|------|-------|
| **SAMâ€‘2** | Extends Segmentâ€‘Anything from images to spatioâ€‘temporal video masks | <https://github.com/facebookresearch/sam2> |
| **SAMURAI** | Pretrained weights + hierarchical decoder built on SAMâ€‘2 | <https://yangchris11.github.io/samurai/> |

Our pipeline downloads SAMURAI checkpoints and drives them
directlyâ€”no need to juggle multiple demos.

---

## 3â€‚Key features
* **Codecâ€‘agnostic input** â€“ autoâ€‘converts `.mov` â†’ `.mp4` if needed  
* **Singleâ€‘click ROI** â€“ select a bounding box on the first frame, then relax  
* **Zeroâ€‘shot multiâ€‘object tracking** â€“ SAMURAI propagates masks frameâ€‘byâ€‘frame  
* **Photogrammetryâ€‘friendly export**
  * `original/` â€“ raw JPEGs with focal length, 35Â mmÂ eq., make/model in EXIF  
  * `masked/`Â Â â€“ backgroundâ€‘removed JPEG +Â binary mask  
* **Optional keyâ€‘frame pickers** â€“ Laplacian variance or ORB matcher  
* **Pure CLI** â€“ no Jupyter dependencies  
* **CUDAâ€‘accelerated** â€“ floatâ€‘16 inference for fast GPUs (falls back to CPU)

---

## 4â€‚Quick start

```bash
# Clone and pull the SAMURAI submodule
git clone https://github.com/<you>/sam2-masking-pipeline.git
cd sam2-masking-pipeline
git submodule update --init --recursive   # brings facebookresearch/sam2 into ./sam2

# Create an isolated Python env (3.9Â â€“Â 3.11)
conda create -n sam2 python=3.10 -y
conda activate sam2

# Install PyTorch that matches your GPU â€“ example: CUDAÂ 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Remaining dependencies
pip install -r requirements.txt

# Download a SAMURAI checkpoint (~2Â GB) into ./checkpoints/
mkdir -p checkpoints
wget -O checkpoints/sam2.1_hiera_large.pt \
     https://dl.fbaipublicfiles.com/samurai/models/sam2.1_hiera_large.pt

# RunÂ ğŸ‰
python -m sam2_masking \
       --video /path/to/MyScan.mov \
       --checkpoint checkpoints/sam2.1_hiera_large.pt \
       --device cuda:0
```

A window will appearâ€”draw a tight box around the object.  
When the progress bar completes you will find:

```
MyScan/
 â”œâ”€ original/
 â”œâ”€ masked/
 â””â”€ keyframes/   # only if you enable keyâ€‘frame extraction
```

---

## 5â€‚Detailed installation notes

| Item | Linux / macOS | Windows |
|------|---------------|---------|
| **System packages** | `sudo apt install ffmpeg mediainfo libgl1` | `choco install ffmpeg mediainfo` |
| **GPU drivers** | NVIDIAÂ 535Â + for CUDAÂ 11.8 | Same |
| **Python** | 3.9Â â€“Â 3.11 via conda/pyenv | Miniconda recommended |

> **CPUâ€‘only?**Â Use `pip install torch==2.2.*` (no CUDA wheel) and run with `--device cpu`.

---

## 6â€‚CLI reference

```
python -m sam2_masking --video <file> [options]

Required
  --video PATH            .mov / .mp4 input

Common options
  --checkpoint PATH       SAMURAI weight file (default: checkpoints/*large.pt)
  --device cuda:0|cpu     Compute device
  --no-convert            Skip the automatic MOVâ†’MP4 step

For full list:
  python -m sam2_masking --help
```

---

## 7â€‚Project structure

```
sam2_masking/           # installable Python package
  â”œâ”€ core.py            # processing logic
  â””â”€ cli.py             # entryâ€‘point (python -m sam2_masking)

sam2/                   # SAMâ€‘2 source (git submodule)
checkpoints/            # large .pt files â€“ ignored by git
docs/                   # demo GIFs / screenshots (optional)
```

---

## 8â€‚Extending the pipeline
* **Multiple objects:** call `predictor.add_new_points_or_box()` per instance.  
* **Keyâ€‘frames:** import `laplacian_stats` or `detect_keyframes` from
  `sam2_masking.core` and bolt them into your script.  
* **Fineâ€‘tuning:** drop in your own checkpoint; config is inferred from
  filename suffix (`*_large.pt`, `*_base_plus.pt`, etc.).

---

## 9â€‚FAQ

| Question | Answer |
|----------|--------|
| Does audio survive the MOVâ†’MP4 step? | Noâ€”OpenCV writes videoâ€‘only. |
| How big is the â€œlargeâ€ checkpoint? | â‰ˆÂ 2Â GB (base â‰ˆÂ 600Â MB, tiny â‰ˆÂ 250Â MB). |
| RTXÂ 20â€‘series support? | Yes; FP16 needs computeÂ 7.0+. Otherwise use `--device cpu`. |
| Official Meta support? | Noâ€”community wrapper. SAMâ€‘2Â &Â SAMURAI are Â©Â MetaÂ AI. |

---

## 10â€‚Cite us

If this tool aids your research, please cite SAMâ€‘2Â /Â SAMURAI:

```bibtex
@inproceedings{kirillov2025sam2,
  title     = {Segment Anything in Video},
  author    = {Kirillov, A. and He, K. and others},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year      = {2025}
}
```

---

## 11â€‚License
* **Wrapper code:** MIT  
* **SAMâ€‘2 submodule:** ApacheÂ 2.0  
* **Model checkpoints:** see SAMURAI licence

Enjoy painless video masking! ğŸš€
